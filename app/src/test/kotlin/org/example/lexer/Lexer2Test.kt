/*
 * This source file was generated by the Gradle 'init' task
 */
package org.example.lexer

import org.junit.jupiter.api.assertDoesNotThrow
import org.junit.jupiter.api.assertThrows
import kotlin.test.Test
import kotlin.test.assertEquals
import kotlin.test.assertFalse
import kotlin.test.assertTrue

class Lexer2Test {
    @Test
    fun testEmptySource() {
        val iterator = TextLexer("").iterator()
        assertTrue(iterator.hasNext())
	assertEquals(TokenType.EOF, iterator.next().type)
        assertFalse(iterator.hasNext())
    }

    @Test
    fun testWhitespacesSource() {
        val iterator = TextLexer("    \t\t\t\n\n\n \r").iterator()
        assertTrue(iterator.hasNext())
        assertEquals(TokenType.EOF, iterator.next().type)
        assertFalse(iterator.hasNext())
    }

    @Test
    fun testSlashCommentsSource() {
        val iterator = TextLexer(" // asd").iterator()
        assertTrue(iterator.hasNext())
        assertEquals(TokenType.EOF, iterator.next().type)
        assertFalse(iterator.hasNext())
    }

    @Test
    fun testHashCommentsSource() {
        val iterator = TextLexer(" # asd").iterator()
        assertTrue(iterator.hasNext())
        assertEquals(TokenType.EOF, iterator.next().type)
        assertFalse(iterator.hasNext())
    }

    @Test
    fun testMultilineCommentsSource() {
        val iterator = TextLexer(" /* a\na\na\n\n */ ").iterator()
        assertTrue(iterator.hasNext())
        assertEquals(TokenType.EOF, iterator.next().type)
        assertFalse(iterator.hasNext())
    }

    @Test
    fun testEmptyMultilineCommentsSource() {
        val iterator = TextLexer(" /**/ ").iterator()
        assertTrue(iterator.hasNext())
        assertEquals(TokenType.EOF, iterator.next().type)
        assertFalse(iterator.hasNext())
    }

    @Test
    fun testManyStarsMultilineCommentsSource() {
        val iterator = TextLexer(" /** /* ***/ ").iterator()
        assertTrue(iterator.hasNext())
        assertEquals(TokenType.EOF, iterator.next().type)
        assertFalse(iterator.hasNext())
    }

    @Test
    fun testFirstSlashDoesNotMatterMultilineCommentsSource() {
        val iterator = TextLexer(" /*///***/ ").iterator()
        assertTrue(iterator.hasNext())
        assertEquals(TokenType.EOF, iterator.next().type)
        assertFalse(iterator.hasNext())
    }

    @Test
    fun testSingleTokenSource() {
        val testCases = listOf(
            Pair("abc", TokenType.IDENTIFIER),
            Pair("BEGIN", TokenType.KEYWORD),
            Pair("=", TokenType.ASSIGN),
            Pair("==", TokenType.OPERATION),
            Pair(",", TokenType.SPECIAL),
        )
        testCases.forEach {
            val lexer = TextLexer(it.first)
            val got = lexer.iterator().next()
            assertEquals(it.second, got.type)
            assertEquals(it.first, got.repr)
            assertEquals(Pos(1, 1), got.pos)
        }
    }

    @Test
    fun testEscapedCharactersInString() {
        val source = """
            "\\\""
        """.trimIndent()

        val lexer = TextLexer(source)
        val tokens = lexer.toList()

        assertEquals(1, tokens.size)
        assertEquals(TokenType.STRING, tokens.first().type)
        assertEquals(Pos(1, 1), tokens.first().pos)
    }

    @Test
    fun testPositionMultiline() {
        val source = """
            id = 1
            c = ; // something /*
            d = 3.3 /*
            
            
            e=2*/e=2
        """.trimIndent()

        val lexer = TextLexer(source)
        val tokens = lexer.toList()
        val expected = listOf(
            Pos(line = 1, col = 1),
            Pos(line = 1, col = 4),
            Pos(line = 1, col = 6),
            Pos(line = 2, col = 1),
            Pos(line = 2, col = 3),
            Pos(line = 2, col = 5),
            Pos(line = 3, col = 1),
            Pos(line = 3, col = 3),
            Pos(line = 3, col = 5),
            Pos(line = 6, col = 6),
            Pos(line = 6, col = 7),
            Pos(line = 6, col = 8),
        )
        assertEquals(expected, tokens.map { it.pos })
    }

    @Test
    fun testTypesMultiline() {
        val source = """
            BEGIN; END; BEGINid; // begin and end
            {
            ${'$'}variable = 000__000000000000000_00000001000 + 0b011101 + 0xaF231 == id;
            /*
            r"raw\str\\\ing\" = "\"not\\\"\\ raw\\"
            */
            r"raw\str\\\ing\" = "\"not\\\"\\ raw\\"
            00000000000123. .12300000000000000000000000000000000000
            00000123.12300000000000000000000000000000000000
            }
        """.trimIndent()

        val lexer = TextLexer(source)
        val tokens = lexer.toList()
        val expected = listOf(
            TokenType.KEYWORD,
            TokenType.SPECIAL,
            TokenType.KEYWORD,
            TokenType.SPECIAL,
            TokenType.IDENTIFIER,
            TokenType.SPECIAL,
            TokenType.SPECIAL,
            TokenType.IDENTIFIER,
            TokenType.ASSIGN,
            TokenType.INT,
            TokenType.OPERATION,
            TokenType.INT,
            TokenType.OPERATION,
            TokenType.INT,
            TokenType.OPERATION,
            TokenType.IDENTIFIER,
            TokenType.SPECIAL,
            TokenType.STRING,
            TokenType.ASSIGN,
            TokenType.STRING,
            TokenType.FIXED_POINT,
            TokenType.FIXED_POINT,
            TokenType.FIXED_POINT,
            TokenType.SPECIAL,
        )

        assertEquals(expected, tokens.map { it.type })
    }

    @Test
    fun testReprMultiline() {
        val source = """
            BEGIN; END; BEGINid; // begin and end
            {
            ${'$'}variable = 000_00000000000000000000000_000000000000000_00000001000 + 0b011101 + 0xaF231 == id;
            /*
            r"raw\str\\\ing\" = "\"not\\\"\\ raw\\"
            */
            r"raw\str\\\ing\" = "\"not\\\"\\ raw\\"
            0000000000000000000123. .1230000000000000000000000000
            00000000000000123.1230000000000000000000000000
            }
        """.trimIndent()

        val lexer = TextLexer(source)
        val tokens = lexer.toList()
        val expected = listOf(
            "BEGIN",
            ";",
            "END",
            ";",
            "BEGINid",
            ";",
            "{",
            "\$variable",
            "=",
            "000_00000000000000000000000_000000000000000_00000001000",
            "+",
            "0b011101",
            "+",
            "0xaF231",
            "==",
            "id",
            ";",
            "r\"raw\\str\\\\\\ing\\\"",
            "=",
            "\"\\\"not\\\\\\\"\\\\ raw\\\\\"",
            "0000000000000000000000000123.",
            ".1230000000000000000000000000",
            "0000000000000000000000000123.1230000000000000000000000000",
            "}",
        )

        assertEquals(expected, tokens.map { it.repr })
    }

    @Test
    fun testDotThrows() {
        assertThrows<Exception> {
            TextLexer(".").toList()
        }
    }

    @Test
    fun testInfiniteMultilineComment() {
        assertThrows<Exception> {
            TextLexer("/* some stuff").toList()
        }
    }

}


